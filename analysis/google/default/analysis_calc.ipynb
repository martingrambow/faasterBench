{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "infile = \"results.pkl\"\n",
    "outfile = \"perfChanges.pkl\"\n",
    "outfile2 = \"accuracy.pkl\"\n",
    "rawData = []\n",
    "accuracy = []\n",
    "samples = 10000\n",
    "CI99 = 100 - 99 # 99% conf\n",
    "df_results = pd.read_pickle(infile)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "platforms = df_results.platform.unique()\n",
    "for platform in platforms:\n",
    "    print(\"analysis for platform \" + platform + \" ...\")\n",
    "\n",
    "    regressions = df_results.regression.unique()\n",
    "    for regression in regressions:\n",
    "        print(\"analysis for regression \" + str(regression) + \"% ...\")\n",
    "\n",
    "        wrapperCounts = df_results.wrapperCount.unique()\n",
    "        for wrapperCount in wrapperCounts:\n",
    "            print(\"analysis for wrapper count \" + str(wrapperCount) + \"...\")\n",
    "\n",
    "            callsPerFunctions = df_results.callsPerFunction.unique()\n",
    "            for calls in callsPerFunctions:\n",
    "                print(\"analysis for calls \" + str(calls) + \"...\")\n",
    "\n",
    "                iterations = df_results.iterations.unique()\n",
    "                for it in iterations:\n",
    "                    print(\"analysis for iterations \" + str(it) + \"...\")\n",
    "\n",
    "                    # faasterBench\n",
    "                    changes = df_results.loc[(df_results[\"mode\"] == 'modeA')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'change'].to_numpy()\n",
    "\n",
    "                    run1 = df_results.loc[(df_results[\"mode\"] == 'modeA')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f1'].to_numpy()\n",
    "                    run2 = df_results.loc[(df_results[\"mode\"] == 'modeA')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f2'].to_numpy()\n",
    "\n",
    "                    #sns.histplot(run1, binwidth=10, color=\"blue\")\n",
    "                    #sns.histplot(run2, binwidth=10, color=\"red\")\n",
    "                    plt.show()\n",
    "\n",
    "                    medPerfChange = (np.median(changes) - 1) * 100\n",
    "                    manySamples = []\n",
    "                    for i in range (0,samples):\n",
    "                        simulatedExperiment = random.choices(changes, k=len(changes))\n",
    "                        manySamples.append(np.median(simulatedExperiment))\n",
    "\n",
    "                    manySamples.sort()\n",
    "\n",
    "                    #medPerfChange = (manySamples[int(len(manySamples)/2)] - 1) * 100\n",
    "                    small = int((samples * CI99) / 100 / 2)\n",
    "                    if small == 0:\n",
    "                        small  = 1\n",
    "                    min = manySamples[small-1]\n",
    "                    min = (min - 1) * 100\n",
    "                    max = manySamples[samples-small-1]\n",
    "                    max = (max - 1) * 100\n",
    "\n",
    "                    print(f\"    faasterBench detects {medPerfChange:.2f}% [{min:.2f}%, {max:.2f}%].\")\n",
    "                    row = {}\n",
    "                    row[\"platform\"] = platform\n",
    "                    row[\"regression\"] = regression\n",
    "                    row[\"wrapperCount\"] = wrapperCount\n",
    "                    row[\"callsPerFunction\"] = calls\n",
    "                    row[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row[\"iterations\"] = it\n",
    "                    row[\"method\"] = \"faasterBench\"\n",
    "                    row[\"change\"] = medPerfChange\n",
    "                    row[\"min\"] = min\n",
    "                    row[\"max\"] = max\n",
    "                    rawData.append(row)\n",
    "\n",
    "                    row2 = {}\n",
    "                    row2[\"method\"] = \"faasterBench\"\n",
    "                    row2[\"regression\"] = regression\n",
    "                    row2[\"measurements\"] = len(changes)\n",
    "                    row2[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row2[\"deviation\"] = abs(medPerfChange-regression)\n",
    "                    row2[\"CIWidth\"] = abs(max-min)\n",
    "                    accuracy.append(row2)\n",
    "\n",
    "                    faasterCI = abs(max-min)\n",
    "\n",
    "                    # traditional\n",
    "                    durations1 = df_results.loc[(df_results[\"mode\"] == 'modeB')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f1'].to_numpy()\n",
    "                    durations2 = df_results.loc[(df_results[\"mode\"] == 'modeC')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f2'].to_numpy()\n",
    "\n",
    "\n",
    "                    durations1.sort()\n",
    "                    durations2.sort()\n",
    "                    pairs = []\n",
    "                    for d1 in durations1:\n",
    "                        for d2 in durations2:\n",
    "                            pairs.append(d2/d1)\n",
    "\n",
    "                    #medPerf1 = np.median(durations1)\n",
    "                    #medPerf2 = np.median(durations2)\n",
    "                    #medPerfChange = ((medPerf2 / medPerf1) - 1) * 100\n",
    "\n",
    "                    medPerfChange = (np.median(pairs) - 1 ) * 100\n",
    "\n",
    "                    manySamples = []\n",
    "                    for i in range (0,samples):\n",
    "                        simulatedExperiment = []\n",
    "                        for i in range(0,len(durations1)):\n",
    "                            simulatedExperiment.append(random.choice(durations2) / random.choice(durations1))\n",
    "\n",
    "                        manySamples.append(np.median(simulatedExperiment))\n",
    "\n",
    "                    manySamples.sort()\n",
    "\n",
    "                    #medPerfChange = (manySamples[int(len(manySamples)/2)] - 1) * 100\n",
    "                    small = int((samples * CI99) / 100 / 2)\n",
    "                    if small == 0:\n",
    "                        small  = 1\n",
    "                    min = manySamples[small-1]\n",
    "                    min = (min - 1) * 100\n",
    "                    max = manySamples[samples-small-1]\n",
    "                    max = (max - 1) * 100\n",
    "\n",
    "                    print(f\"    traditional detects {medPerfChange:.2f}% [{min:.2f}%, {max:.2f}%].\")\n",
    "                    row = {}\n",
    "                    row[\"platform\"] = platform\n",
    "                    row[\"regression\"] = regression\n",
    "                    row[\"wrapperCount\"] = wrapperCount\n",
    "                    row[\"callsPerFunction\"] = calls\n",
    "                    row[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row[\"iterations\"] = it\n",
    "                    row[\"method\"] = \"traditional\"\n",
    "                    row[\"change\"] = medPerfChange\n",
    "                    row[\"min\"] = min\n",
    "                    row[\"max\"] = max\n",
    "                    rawData.append(row)\n",
    "\n",
    "                    row2 = {}\n",
    "                    row2[\"method\"] = \"traditional\"\n",
    "                    row2[\"regression\"] = regression\n",
    "                    row2[\"measurements\"] = len(durations1)\n",
    "                    row2[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row2[\"deviation\"] = abs(medPerfChange-regression)\n",
    "                    row2[\"CIWidth\"] = abs(max-min)\n",
    "                    accuracy.append(row2)\n",
    "\n",
    "                    tradCI = abs(max-min)\n",
    "\n",
    "                    print(f\"    faasterCI is {(tradCI - faasterCI):.2f} smaller\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis for platform google ...\n",
      "analysis for regression 0% ...\n",
      "analysis for wrapper count 10...\n",
      "analysis for calls 10...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 0.30% [0.00%, 0.60%].\n",
      "    traditional detects 0.36% [-1.69%, 2.37%].\n",
      "    faasterCI is 3.46 smaller\n",
      "analysis for calls 25...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 0.00% [-0.40%, 0.34%].\n",
      "    traditional detects -0.52% [-3.32%, 2.30%].\n",
      "    faasterCI is 4.88 smaller\n",
      "analysis for calls 5...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects -0.20% [-0.99%, 0.34%].\n",
      "    traditional detects -0.21% [-3.25%, 2.33%].\n",
      "    faasterCI is 4.24 smaller\n",
      "analysis for wrapper count 5...\n",
      "analysis for calls 10...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 0.00% [-0.50%, 0.80%].\n",
      "    traditional detects 0.19% [-2.22%, 2.71%].\n",
      "    faasterCI is 3.63 smaller\n",
      "analysis for calls 25...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects -0.51% [-1.15%, 0.00%].\n",
      "    traditional detects -0.14% [-4.04%, 4.05%].\n",
      "    faasterCI is 6.93 smaller\n",
      "analysis for calls 5...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects -0.78% [-1.85%, 0.99%].\n",
      "    traditional detects -0.71% [-4.19%, 3.06%].\n",
      "    faasterCI is 4.42 smaller\n",
      "analysis for regression 5% ...\n",
      "analysis for wrapper count 10...\n",
      "analysis for calls 10...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 2.86% [2.50%, 3.22%].\n",
      "    traditional detects 6.08% [3.05%, 9.88%].\n",
      "    faasterCI is 6.11 smaller\n",
      "analysis for calls 25...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 2.74% [2.30%, 3.36%].\n",
      "    traditional detects 6.22% [3.45%, 9.37%].\n",
      "    faasterCI is 4.87 smaller\n",
      "analysis for calls 5...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 2.75% [2.13%, 3.61%].\n",
      "    traditional detects 4.46% [1.87%, 8.30%].\n",
      "    faasterCI is 4.96 smaller\n",
      "analysis for wrapper count 5...\n",
      "analysis for calls 10...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 2.50% [2.20%, 3.96%].\n",
      "    traditional detects 4.05% [1.19%, 8.20%].\n",
      "    faasterCI is 5.25 smaller\n",
      "analysis for calls 25...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 2.72% [2.06%, 3.60%].\n",
      "    traditional detects 6.12% [3.12%, 9.44%].\n",
      "    faasterCI is 4.78 smaller\n",
      "analysis for calls 5...\n",
      "analysis for iterations 3...\n",
      "    faasterBench detects 2.22% [2.20%, 2.57%].\n",
      "    traditional detects 6.45% [1.65%, 12.30%].\n",
      "    faasterCI is 10.29 smaller\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_changes = pd.DataFrame(rawData)\n",
    "df_changes.sort_values(\"callsPerFunctionInt\", inplace=True)\n",
    "df_changes.head()\n",
    "df_changes.describe()\n",
    "df_changes.to_pickle(outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_accuracy = pd.DataFrame(accuracy)\n",
    "df_accuracy.head()\n",
    "df_accuracy.describe()\n",
    "df_accuracy.to_pickle(outfile2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}