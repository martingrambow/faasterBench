{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "infile = \"results.pkl\"\n",
    "outfile = \"perfChanges.pkl\"\n",
    "outfile2 = \"accuracy.pkl\"\n",
    "rawData = []\n",
    "accuracy = []\n",
    "samples = 10000\n",
    "CI99 = 100 - 99 # 99% conf\n",
    "df_results = pd.read_pickle(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gov/faasterbench/analysis/aws/analysis_calc.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gov/faasterbench/analysis/aws/analysis_calc.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m platforms \u001b[39m=\u001b[39m df_results\u001b[39m.\u001b[39mplatform\u001b[39m.\u001b[39munique()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gov/faasterbench/analysis/aws/analysis_calc.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m platform \u001b[39min\u001b[39;00m platforms:\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gov/faasterbench/analysis/aws/analysis_calc.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39manalysis for platform \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m platform \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m ...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_results' is not defined"
     ]
    }
   ],
   "source": [
    "platforms = df_results.platform.unique()\n",
    "for platform in platforms:\n",
    "    print(\"analysis for platform \" + platform + \" ...\")\n",
    "\n",
    "    regressions = df_results.regression.unique()\n",
    "    for regression in regressions:\n",
    "        print(\"analysis for regression \" + str(regression) + \"% ...\")\n",
    "\n",
    "        wrapperCounts = df_results.wrapperCount.unique()\n",
    "        for wrapperCount in wrapperCounts:\n",
    "            print(\"analysis for wrapper count \" + str(wrapperCount) + \"...\")\n",
    "\n",
    "            callsPerFunctions = df_results.callsPerFunction.unique()\n",
    "            for calls in callsPerFunctions:\n",
    "                print(\"analysis for calls \" + str(calls) + \"...\")\n",
    "\n",
    "                iterations = df_results.iterations.unique()\n",
    "                for it in iterations:\n",
    "                    print(\"analysis for iterations \" + str(it) + \"...\")\n",
    "\n",
    "                    # faasterBench\n",
    "                    changes = df_results.loc[(df_results[\"mode\"] == 'modeA')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'change'].to_numpy()\n",
    "\n",
    "                    run1 = df_results.loc[(df_results[\"mode\"] == 'modeA')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f1'].to_numpy()\n",
    "                    run2 = df_results.loc[(df_results[\"mode\"] == 'modeA')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f2'].to_numpy()\n",
    "\n",
    "                    #sns.histplot(run1, binwidth=10, color=\"blue\")\n",
    "                    #sns.histplot(run2, binwidth=10, color=\"red\")\n",
    "                    plt.show()\n",
    "\n",
    "                    medPerfChange = (np.median(changes) - 1) * 100\n",
    "                    manySamples = []\n",
    "                    for i in range (0,samples):\n",
    "                        simulatedExperiment = random.choices(changes, k=len(changes))\n",
    "                        manySamples.append(np.median(simulatedExperiment))\n",
    "\n",
    "                    manySamples.sort()\n",
    "\n",
    "                    #medPerfChange = (manySamples[int(len(manySamples)/2)] - 1) * 100\n",
    "                    small = int((samples * CI99) / 100 / 2)\n",
    "                    if small == 0:\n",
    "                        small  = 1\n",
    "                    min = manySamples[small-1]\n",
    "                    min = (min - 1) * 100\n",
    "                    max = manySamples[samples-small-1]\n",
    "                    max = (max - 1) * 100\n",
    "\n",
    "                    print(f\"    faasterBench detects {medPerfChange:.2f}% [{min:.2f}%, {max:.2f}%].\")\n",
    "                    row = {}\n",
    "                    row[\"platform\"] = platform\n",
    "                    row[\"regression\"] = regression\n",
    "                    row[\"wrapperCount\"] = wrapperCount\n",
    "                    row[\"callsPerFunction\"] = calls\n",
    "                    row[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row[\"iterations\"] = it\n",
    "                    row[\"method\"] = \"faasterBench\"\n",
    "                    row[\"change\"] = medPerfChange\n",
    "                    row[\"min\"] = min\n",
    "                    row[\"max\"] = max\n",
    "                    rawData.append(row)\n",
    "\n",
    "                    row2 = {}\n",
    "                    row2[\"method\"] = \"faasterBench\"\n",
    "                    row2[\"regression\"] = regression\n",
    "                    row2[\"measurements\"] = len(changes)\n",
    "                    row2[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row2[\"deviation\"] = abs(medPerfChange-regression)\n",
    "                    row2[\"CIWidth\"] = abs(max-min)\n",
    "                    accuracy.append(row2)\n",
    "\n",
    "                    faasterCI = abs(max-min)\n",
    "\n",
    "\n",
    "                    # traditional\n",
    "                    durations1 = df_results.loc[(df_results[\"mode\"] == 'modeB')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f1'].to_numpy()\n",
    "                    durations2 = df_results.loc[(df_results[\"mode\"] == 'modeC')\n",
    "                                             & (df_results[\"platform\"] == platform)\n",
    "                                             & (df_results[\"regression\"] == regression)\n",
    "                                             & (df_results[\"wrapperCount\"] == wrapperCount)\n",
    "                                             & (df_results[\"callsPerFunction\"] == calls)\n",
    "                                             & (df_results[\"iterations\"] == it),'f2'].to_numpy()\n",
    "\n",
    "\n",
    "                    durations1.sort()\n",
    "                    durations2.sort()\n",
    "                    pairs = []\n",
    "                    for d1 in durations1:\n",
    "                        for d2 in durations2:\n",
    "                            pairs.append(d2/d1)\n",
    "\n",
    "                    #medPerf1 = np.median(durations1)\n",
    "                    #medPerf2 = np.median(durations2)\n",
    "                    #medPerfChange = ((medPerf2 / medPerf1) - 1) * 100\n",
    "\n",
    "                    medPerfChange = (np.median(pairs) - 1 ) * 100\n",
    "\n",
    "                    manySamples = []\n",
    "                    for i in range (0,samples):\n",
    "                        simulatedExperiment = []\n",
    "                        for i in range(0,len(durations1)):\n",
    "                            simulatedExperiment.append(random.choice(durations2) / random.choice(durations1))\n",
    "\n",
    "                        manySamples.append(np.median(simulatedExperiment))\n",
    "\n",
    "                    manySamples.sort()\n",
    "\n",
    "                    #medPerfChange = (manySamples[int(len(manySamples)/2)] - 1) * 100\n",
    "                    small = int((samples * CI99) / 100 / 2)\n",
    "                    if small == 0:\n",
    "                        small  = 1\n",
    "                    min = manySamples[small-1]\n",
    "                    min = (min - 1) * 100\n",
    "                    max = manySamples[samples-small-1]\n",
    "                    max = (max - 1) * 100\n",
    "\n",
    "                    print(f\"    traditional detects {medPerfChange:.2f}% [{min:.2f}%, {max:.2f}%].\")\n",
    "                    row = {}\n",
    "                    row[\"platform\"] = platform\n",
    "                    row[\"regression\"] = regression\n",
    "                    row[\"wrapperCount\"] = wrapperCount\n",
    "                    row[\"callsPerFunction\"] = calls\n",
    "                    row[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row[\"iterations\"] = it\n",
    "                    row[\"method\"] = \"traditional\"\n",
    "                    row[\"change\"] = medPerfChange\n",
    "                    row[\"min\"] = min\n",
    "                    row[\"max\"] = max\n",
    "                    rawData.append(row)\n",
    "\n",
    "                    row2 = {}\n",
    "                    row2[\"method\"] = \"traditional\"\n",
    "                    row2[\"regression\"] = regression\n",
    "                    row2[\"measurements\"] = len(durations1)\n",
    "                    row2[\"callsPerFunctionInt\"] = int(calls)\n",
    "                    row2[\"deviation\"] = abs(medPerfChange-regression)\n",
    "                    row2[\"CIWidth\"] = abs(max-min)\n",
    "                    accuracy.append(row2)\n",
    "\n",
    "                    tradCI = abs(max-min)\n",
    "\n",
    "                    print(f\"    faasterCI is {(tradCI - faasterCI):.2f} smaller\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_changes = pd.DataFrame(rawData)\n",
    "df_changes.sort_values(\"callsPerFunctionInt\", inplace=True)\n",
    "df_changes.head()\n",
    "df_changes.describe()\n",
    "df_changes.to_pickle(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_accuracy = pd.DataFrame(accuracy)\n",
    "df_accuracy.head()\n",
    "df_accuracy.describe()\n",
    "df_accuracy.to_pickle(outfile2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
